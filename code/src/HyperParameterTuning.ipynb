{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aab9b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3cf3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the class\n",
    "class ModelValidator:\n",
    "    # Creating attributes that define and use later\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.cv_results = None\n",
    "        self.cv_mean = None\n",
    "        self.cv_top_lr = None\n",
    "        self.cv_top_dt = None\n",
    "        self.top_hp_lr = None\n",
    "        self.top_3_lr = None\n",
    "        self.top_hp_dt = None\n",
    "        self.top_3_dt = None\n",
    "        self.top_model_lr = None\n",
    "        self.top_model_dt = None\n",
    "\n",
    "    # Defining the cross-validation method\n",
    "    def cross_validate(self, model, kfolds=10):\n",
    "        self.cv_results = cross_val_score(model, self.X_train, self.y_train, cv=kfolds)\n",
    "        self.cv_mean = np.mean(self.cv_results)\n",
    "        return self.cv_mean\n",
    "\n",
    "    # Defining my logistic regression improving method.\n",
    "    def check_log_reg(self, cv_now=False):\n",
    "        # Create a dictionary with ranges on the hyperparameters\n",
    "        log_reg_hyperp = {\n",
    "            'C': [0.01, 0.1, 1.0, 10, 100, 1000],\n",
    "            'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "            'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky'],\n",
    "            'tol': [1e-5, 1e-4, 1e-3],\n",
    "            'random_state': [42],  # Set random state to 42\n",
    "            'max_iter': [1000, 10000]\n",
    "        }\n",
    "\n",
    "        top_3_lr = []\n",
    "\n",
    "        # Instantiating the model and looping through the different combinations of hyperparameters for a logistic regression model.\n",
    "        model_inst = LogisticRegression(random_state=42)  # Set random state to 42\n",
    "        for params in ParameterGrid(log_reg_hyperp):\n",
    "            try:\n",
    "                model_inst.set_params(**params)\n",
    "                model_inst.fit(self.X_train, self.y_train)\n",
    "                y_pred = model_inst.predict(self.X_test)\n",
    "                test_accuracy = accuracy_score(self.y_test, y_pred)\n",
    "                if cv_now:\n",
    "                    cv_accuracy = self.cross_validate(model_inst)\n",
    "                    top_3_lr.append((params, cv_accuracy, test_accuracy))\n",
    "                else:\n",
    "                    top_3_lr.append((params, test_accuracy))\n",
    "\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "\n",
    "        top_3_lr.sort(key=lambda x: x[-1], reverse=True)\n",
    "        top_hp_lr = top_3_lr[:1]\n",
    "        top_3_lr = top_3_lr[:3]\n",
    "\n",
    "        # Saving the attributes\n",
    "        self.top_3_lr = top_3_lr\n",
    "        self.top_hp_lr = top_hp_lr\n",
    "        self.top_model_lr = LogisticRegression(random_state=42).set_params(**self.top_hp_lr[0][0]).fit(self.X_train,\n",
    "                                                                                                        self.y_train)\n",
    "\n",
    "    # Defining a model method to loop and find the best combination of hyperparameters for my decision tree\n",
    "    def check_desc_tree(self, cv_now=False):\n",
    "        # Creating a dictionary with the hyperparameters combinations\n",
    "        decision_tree_hyperp = {\n",
    "            'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "            'max_depth': range(1, 5),\n",
    "            'min_samples_split': range(2, 4),\n",
    "            'min_samples_leaf': range(1, 4),\n",
    "            'random_state': [42],  # Set random state to 42\n",
    "        }\n",
    "\n",
    "        top_3_dt = []\n",
    "\n",
    "        # Instantiating the model, looping through them and finding top performers\n",
    "        model_inst = DecisionTreeClassifier(random_state=42)  # Set random state to 42\n",
    "        for params in ParameterGrid(decision_tree_hyperp):\n",
    "            try:\n",
    "                model_inst.set_params(**params)\n",
    "                model_inst.fit(self.X_train, self.y_train)\n",
    "                y_pred = model_inst.predict(self.X_test)\n",
    "                test_accuracy = accuracy_score(self.y_test, y_pred)\n",
    "                if cv_now:\n",
    "                    cv_accuracy = self.cross_validate(model_inst)\n",
    "                    top_3_dt.append((params, cv_accuracy, test_accuracy))\n",
    "                else:\n",
    "                    top_3_dt.append((params, test_accuracy))\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "\n",
    "        top_3_dt.sort(key=lambda x: x[-1], reverse=True)\n",
    "        top_hp_dt = top_3_dt[:1]\n",
    "        top_3_dt = top_3_dt[:3]\n",
    "\n",
    "        # Saving attributes\n",
    "        self.top_3_dt = top_3_dt\n",
    "        self.top_hp_dt = top_hp_dt\n",
    "        self.top_model_dt = DecisionTreeClassifier(random_state=42).set_params(**self.top_hp_dt[0][0]).fit(self.X_train,\n",
    "                                                                                                           self.y_train)\n",
    "\n",
    "    # Plotting Confusion Matrix for top-performing models\n",
    "    def plot_confusion_matrix(self):\n",
    "        if self.top_hp_lr[0][-1] > self.top_hp_dt[0][-1]:\n",
    "            top_model = LogisticRegression(random_state=42).set_params(**self.top_hp_lr[0][0]).fit(self.X_train,\n",
    "                                                                                                     self.y_train)\n",
    "            model_type = 'Logistic Regression'\n",
    "        else:\n",
    "            top_model = DecisionTreeClassifier(random_state=42).set_params(**self.top_hp_dt[0][0]).fit(self.X_train,\n",
    "                                                                                                      self.y_train)\n",
    "            model_type = 'Decision Tree'\n",
    "        ConfusionMatrixDisplay.from_estimator(top_model, self.X_test, self.y_test)\n",
    "        plt.title(f\"Confusion Matrix for {model_type}\")\n",
    "\n",
    "    # Plotting ROC Curve for top-performing models\n",
    "    def plot_roc_curve(self):\n",
    "        if self.top_hp_lr[0][-1] > self.top_hp_dt[0][-1]:\n",
    "            top_model = LogisticRegression(random_state=42).set_params(**self.top_hp_lr[0][0]).fit(self.X_train,\n",
    "                                                                                                     self.y_train)\n",
    "            model_type = 'Logistic Regression'\n",
    "        else:\n",
    "            top_model = DecisionTreeClassifier(random_state=42).set_params(**self.top_hp_dt[0][0]).fit(self.X_train,\n",
    "                                                                                                      self.y_train)\n",
    "            model_type = 'Decision Tree'\n",
    "        RocCurveDisplay.from_estimator(top_model, self.X_test, self.y_test)\n",
    "        plt.title(f\"ROC Curve for {model_type}\")\n",
    "\n",
    "    # Determining most important features for my data\n",
    "    def feature_importance(self, n=10):\n",
    "        if self.top_hp_lr[0][-1] < self.top_hp_dt[0][-1]:\n",
    "            top_model = DecisionTreeClassifier(random_state=42).set_params(**self.top_hp_dt[0][0])\n",
    "            features_used = self.X_train.columns\n",
    "            top_model.fit(self.X_train, self.y_train)\n",
    "            feature_importance = list(zip(top_model.feature_importances_, features_used))\n",
    "        else:\n",
    "            top_model = LogisticRegression(random_state=42).set_params(**self.top_hp_lr[0][0])\n",
    "            top_model.fit(self.X_train, self.y_train)\n",
    "            features_used = self.X_train.columns\n",
    "            feature_importance = list(zip(abs(top_model.coef_[0]), features_used))\n",
    "\n",
    "        feature_importance.sort(key=lambda x: x[0], reverse=True)\n",
    "        return feature_importance[:n]\n",
    "\n",
    "    # Creating a method to obtain the score DataFrame\n",
    "    def scores(self, both_models=False):\n",
    "        dt_y_hat_train = self.top_model_dt.predict(self.X_train)\n",
    "        dt_y_hat_test = self.top_model_dt.predict(self.X_test)\n",
    "        lr_y_hat_train = self.top_model_lr.predict(self.X_train)\n",
    "        lr_y_hat_test = self.top_model_lr.predict(self.X_test)\n",
    "        self.cv_top_lr = self.top_hp_lr[0][1]\n",
    "        self.cv_top_dt = self.top_hp_dt[0][1]\n",
    "\n",
    "        dt_df = {\n",
    "            'Accuracy train': round(accuracy_score(self.y_train, dt_y_hat_train), 3),\n",
    "            'Accuracy test': round(accuracy_score(self.y_test, dt_y_hat_test), 3),\n",
    "            'Recall train': round(recall_score(self.y_train, dt_y_hat_train), 3),\n",
    "            'Recall test': round(recall_score(self.y_test, dt_y_hat_test), 3),\n",
    "            'Precision train': round(precision_score(self.y_train, dt_y_hat_train), 3),\n",
    "            'Precision test': round(precision_score(self.y_test, dt_y_hat_test), 3),\n",
    "            'F1 train': round(f1_score(self.y_train, dt_y_hat_train), 3),\n",
    "            'F1 test': round(f1_score(self.y_test, dt_y_hat_test), 3),\n",
    "            'CV results': round(self.cv_top_dt, 3)\n",
    "        }\n",
    "\n",
    "        lr_df = {\n",
    "            'Accuracy train': round(accuracy_score(self.y_train, lr_y_hat_train), 3),\n",
    "            'Accuracy test': round(accuracy_score(self.y_test, lr_y_hat_test), 3),\n",
    "            'Recall train': round(recall_score(self.y_train, lr_y_hat_train), 3),\n",
    "            'Recall test': round(recall_score(self.y_test, lr_y_hat_test), 3),\n",
    "            'Precision train': round(precision_score(self.y_train, lr_y_hat_train), 3),\n",
    "            'Precision test': round(precision_score(self.y_test, lr_y_hat_test), 3),\n",
    "            'F1 train': round(f1_score(self.y_train, lr_y_hat_train), 3),\n",
    "            'F1 test': round(f1_score(self.y_test, lr_y_hat_test), 3),\n",
    "            'CV results': round(self.cv_top_lr, 3)\n",
    "        }\n",
    "\n",
    "        decision_tree_df = pd.DataFrame(list(dt_df.values()), index=dt_df.keys(), columns=['Decision Tree'])\n",
    "        logistic_regression_df = pd.DataFrame(list(lr_df.values()), index=lr_df.keys(),\n",
    "                                               columns=['Logistic Regression'])\n",
    "\n",
    "        if both_models:\n",
    "            df = pd.concat([decision_tree_df, logistic_regression_df], axis=1)\n",
    "            return df\n",
    "        else:\n",
    "            if self.top_hp_lr[0][-1] < self.top_hp_dt[0][-1]:\n",
    "                return decision_tree_df\n",
    "            else:\n",
    "                return logistic_regression_df\n",
    "\n",
    "    # Creating a method to plot the decision tree\n",
    "    def plot_tree(self):\n",
    "        f, ax = plt.subplots(figsize=(8, 8))\n",
    "        plot_tree(self.top_model_dt, ax=ax)\n",
    "        plt.title('Decision Tree Classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd10035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
